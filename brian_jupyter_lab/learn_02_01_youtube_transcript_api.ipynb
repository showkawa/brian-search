{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangChain + Deep Lake + ChatGPT-3.5 快速学习github开源代码 \n",
    "\n",
    "##### 1. dependences\n",
    "##### 1.1 deeplake - online vectors DB\n",
    "##### 1.2 tiktoken - convert the text to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed langchain-0.0.270\n"
     ]
    }
   ],
   "source": [
    "#%pip install langchain deeplake openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyJhbGciOiJIUzUxMiIsImlhdCI6MTY5MjcxMDkzMywiZXhwIjoxNjkyNzk3MzE1fQ.eyJpZCI6Imh1YW5nbGlhbmcifQ.QDGT0EpGKJh97f07eXN4GUbHCqyyQTIJ8-7JR3WPqr9RDjV-n1kEiQbDfU2apS2qx3XCkV9AV9tlUJoaBVM5dQ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DeepLake\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ.get('ACTIVELOOP_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\" env --> {os.environ['OPENAI_API_KEY']}\")\n",
    "#print(f\" env --> {os.environ['DEEP_LAKE_API_KEY']}\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(disallowed_special=(),openai_api_key=os.environ['OPENAI_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'youtube-transcript-api'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jdepoix/youtube-transcript-api.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "root_dir = '../brian_jupyter_lab/youtube-transcript-api/'\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        try:\n",
    "            loader = TextLoader(os.path.join(dirpath, file),encoding='utf-8')\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "666"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 3102, which is longer than the specified 2000\n",
      "Created a chunk of size 2278, which is longer than the specified 2000\n",
      "Created a chunk of size 3421, which is longer than the specified 2000\n",
      "Created a chunk of size 2927, which is longer than the specified 2000\n",
      "Created a chunk of size 2215, which is longer than the specified 2000\n",
      "Created a chunk of size 2215, which is longer than the specified 2000\n",
      "Created a chunk of size 2257, which is longer than the specified 2000\n",
      "Created a chunk of size 2920, which is longer than the specified 2000\n",
      "Created a chunk of size 3081, which is longer than the specified 2000\n",
      "Created a chunk of size 2273, which is longer than the specified 2000\n",
      "Created a chunk of size 2927, which is longer than the specified 2000\n",
      "Created a chunk of size 2153, which is longer than the specified 2000\n",
      "Created a chunk of size 2764, which is longer than the specified 2000\n",
      "Created a chunk of size 2918, which is longer than the specified 2000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# 对文本切块，1500的字符切一次，每个切块的上下文件有10个字符的重叠\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=20)\n",
    "texts= text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "872"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://huangliang/bjl_youtube_transcript_api_source already exists, loading from the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: (\"Connection broken: InvalidChunkLength(got length b'', 0 bytes read)\", InvalidChunkLength(got length b'', 0 bytes read)).\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m username\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhuangliang\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m db \u001b[39m=\u001b[39m DeepLake(dataset_path\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhub://\u001b[39m\u001b[39m{\u001b[39;00musername\u001b[39m}\u001b[39;00m\u001b[39m/bjl_youtube_transcript_api_source\u001b[39m\u001b[39m\"\u001b[39m, embedding\u001b[39m=\u001b[39membeddings)\n\u001b[1;32m----> 3\u001b[0m db\u001b[39m.\u001b[39;49madd_documents(texts)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\base.py:103\u001b[0m, in \u001b[0;36mVectorStore.add_documents\u001b[1;34m(self, documents, **kwargs)\u001b[0m\n\u001b[0;32m    101\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m    102\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_texts(texts, metadatas, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\vectorstores\\deeplake.py:220\u001b[0m, in \u001b[0;36mDeepLake.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(texts) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`texts` parameter shouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be empty.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 220\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvectorstore\u001b[39m.\u001b[39;49madd(\n\u001b[0;32m    221\u001b[0m     text\u001b[39m=\u001b[39;49mtexts,\n\u001b[0;32m    222\u001b[0m     metadata\u001b[39m=\u001b[39;49mmetadatas,\n\u001b[0;32m    223\u001b[0m     embedding_data\u001b[39m=\u001b[39;49mtexts,\n\u001b[0;32m    224\u001b[0m     embedding_tensor\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    225\u001b[0m     embedding_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents,  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    226\u001b[0m     return_ids\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    227\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    228\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeplake\\core\\vectorstore\\deeplake_vectorstore.py:282\u001b[0m, in \u001b[0;36mVectorStore.add\u001b[1;34m(self, embedding_function, embedding_data, embedding_tensor, total_samples_processed, return_ids, num_workers, ingestion_batch_size, **tensors)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[39massert\u001b[39;00m id_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    280\u001b[0m utils\u001b[39m.\u001b[39mcheck_length_of_each_tensor(processed_tensors)\n\u001b[1;32m--> 282\u001b[0m dataset_utils\u001b[39m.\u001b[39;49mextend_or_ingest_dataset(\n\u001b[0;32m    283\u001b[0m     processed_tensors\u001b[39m=\u001b[39;49mprocessed_tensors,\n\u001b[0;32m    284\u001b[0m     dataset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset,\n\u001b[0;32m    285\u001b[0m     embedding_function\u001b[39m=\u001b[39;49membedding_function,\n\u001b[0;32m    286\u001b[0m     embedding_data\u001b[39m=\u001b[39;49membedding_data,\n\u001b[0;32m    287\u001b[0m     embedding_tensor\u001b[39m=\u001b[39;49membedding_tensor,\n\u001b[0;32m    288\u001b[0m     ingestion_batch_size\u001b[39m=\u001b[39;49mingestion_batch_size \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mingestion_batch_size,\n\u001b[0;32m    289\u001b[0m     num_workers\u001b[39m=\u001b[39;49mnum_workers \u001b[39mor\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_workers,\n\u001b[0;32m    290\u001b[0m     total_samples_processed\u001b[39m=\u001b[39;49mtotal_samples_processed,\n\u001b[0;32m    291\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[0;32m    292\u001b[0m )\n\u001b[0;32m    294\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mcommit(allow_empty\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    295\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose:\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\deeplake\\core\\vectorstore\\vector_search\\dataset\\dataset.py:414\u001b[0m, in \u001b[0;36mextend_or_ingest_dataset\u001b[1;34m(processed_tensors, dataset, embedding_function, embedding_tensor, embedding_data, ingestion_batch_size, num_workers, total_samples_processed, logger)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[39mif\u001b[39;00m embedding_function:\n\u001b[0;32m    411\u001b[0m     \u001b[39mfor\u001b[39;00m func, data, tensor \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    412\u001b[0m         embedding_function, embedding_data, embedding_tensor\n\u001b[0;32m    413\u001b[0m     ):\n\u001b[1;32m--> 414\u001b[0m         embedded_data \u001b[39m=\u001b[39m func(data)\n\u001b[0;32m    415\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m             embedded_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(embedded_data, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:478\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    467\u001b[0m \n\u001b[0;32m    468\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    475\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    476\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:364\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    361\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    363\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 364\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    365\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m    366\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtokens[i : i \u001b[39m+\u001b[39;49m _chunk_size],\n\u001b[0;32m    367\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_invocation_params,\n\u001b[0;32m    368\u001b[0m     )\n\u001b[0;32m    369\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    371\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[0;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:314\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    312\u001b[0m is_explicit_retry \u001b[39m=\u001b[39m fut\u001b[39m.\u001b[39mfailed \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(fut\u001b[39m.\u001b[39mexception(), TryAgain)\n\u001b[0;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (is_explicit_retry \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry(retry_state)):\n\u001b[1;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m fut\u001b[39m.\u001b[39;49mresult()\n\u001b[0;32m    316\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mafter(retry_state)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tenacity\\__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[0;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain\\embeddings\\openai.py:104\u001b[0m, in \u001b[0;36membed_with_retry.<locals>._embed_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_embed_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m--> 104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[0;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    597\u001b[0m         method,\n\u001b[0;32m    598\u001b[0m         abs_url,\n\u001b[0;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\hh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "username=\"huangliang\"\n",
    "db = DeepLake(dataset_path=f\"hub://{username}/bjl_youtube_transcript_api_source\", embedding=embeddings)\n",
    "db.add_documents(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in hub://huangliang/bjl_youtube_transcript_api_source already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "db = DeepLake(dataset_path='hub://huangliang/bjl_youtube_transcript_api_source', read_only=True,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=db.as_retriever()\n",
    "#distance_metric计算两个的点的距离\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "#fetch_k 从文档中要检索的数据点的数据\n",
    "retriever.search_kwargs['fetch_k'] = 100\n",
    "retriever.search_kwargs['maximal_marginal_relevance'] = True\n",
    "#k 返回相似度最高的向量的数量  \n",
    "retriever.search_kwargs['k'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-16k\",temperature=0,\n",
    "callbacks=[StreamingStdOutCallbackHandler()],streaming=True,)\n",
    "qa = ConversationalRetrievalChain.from_llm(model, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      " what dose youtube-transcript-api work? \n",
      "\n",
      "A:\n",
      " The YouTube Transcript API is a Python library that allows you to retrieve the transcript or subtitles for a given YouTube video. It can also handle automatically generated subtitles and supports translating subtitles. The API does not require a headless browser like other solutions, making it more efficient. You can use it to extract the transcript/subtitles and save them to a file or use them in other applications. \n",
      "\n",
      "Q:\n",
      " How to use youtube-transcript-api? \n",
      "\n",
      "A:\n",
      " To use the youtube-transcript-api, you can follow these steps:\n",
      "\n",
      "1. Install the youtube-transcript-api package using pip:\n",
      "   ```\n",
      "   pip install youtube-transcript-api\n",
      "   ```\n",
      "\n",
      "2. Import the YouTubeTranscriptApi class in your Python script:\n",
      "   ```python\n",
      "   from youtube_transcript_api import YouTubeTranscriptApi\n",
      "   ```\n",
      "\n",
      "3. Use the `get_transcript` method to retrieve the transcript for a specific YouTube video. Pass the video ID as the argument:\n",
      "   ```python\n",
      "   transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
      "   ```\n",
      "\n",
      "   Note: Replace `video_id` with the actual ID of the YouTube video you want to retrieve the transcript for.\n",
      "\n",
      "4. The `transcript` variable will contain the transcript data. You can then process or display the transcript as needed.\n",
      "\n",
      "Here's an example that prints the text of each caption in the transcript:\n",
      "```python\n",
      "from youtube_transcript_api import YouTubeTranscriptApi\n",
      "\n",
      "video_id = \"your_video_id\"\n",
      "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
      "\n",
      "for caption in transcript:\n",
      "    print(caption['text'])\n",
      "```\n",
      "\n",
      "Remember to replace `\"your_video_id\"` with the actual ID of the YouTube video you want to retrieve the transcript for.\n",
      "\n",
      "You can also refer to the [official documentation](https://github.com/jdepoix/youtube-transcript-api) for more information and examples on how to use the youtube-transcript-api. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"what dose youtube-transcript-api work?\",\n",
    "    \"How to use youtube-transcript-api?\"\n",
    "]\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa({\"question\":question,\"chat_history\":chat_history})\n",
    "    chat_history.append((question,result['answer']))\n",
    "    print(f\"Q:\\n {question} \\n\")\n",
    "    print(f\"A:\\n {result['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question,chat_history):\n",
    "    res = qa({\"question\":question,\"chat_history\":chat_history})\n",
    "    print(f\"Q:\\n {question} \\n\")\n",
    "    print(f\"A:\\n {res['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      " If i want to use into retrieve the transcript/subtitles for bilibili, what's python source code in youtube-transcript-api should enhance ? \n",
      "\n",
      "A:\n",
      " The YouTube Transcript/Subtitle API is specifically designed for retrieving transcripts/subtitles from YouTube videos. It is not directly compatible with Bilibili. \n",
      "\n",
      "To retrieve transcripts/subtitles from Bilibili, you would need to use a different API or method that is specifically designed for Bilibili. Unfortunately, I don't have information on a specific API or method for retrieving Bilibili transcripts/subtitles. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"If i want to use into retrieve the transcript/subtitles for bilibili, what's python source code in youtube-transcript-api should enhance ?\",chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q:\n",
      " Can tell me what's _transcripts.py do? \n",
      "\n",
      "A:\n",
      " The `_transcripts.py` module provides classes and methods for working with YouTube transcripts. It includes the `TranscriptList` class, which represents a list of available transcripts for a YouTube video, and the `Transcript` class, which represents a single transcript.\n",
      "\n",
      "The `TranscriptList` class provides methods for finding specific transcripts based on language and type (generated or manually created). It also provides methods for fetching the transcript data and translating the transcript to a different language.\n",
      "\n",
      "The `Transcript` class provides properties for accessing metadata about the transcript, such as the video ID, language, and whether it is generated or manually created. It also provides a method for fetching the transcript data.\n",
      "\n",
      "Overall, the `_transcripts.py` module is responsible for retrieving and managing YouTube transcripts. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"Can tell me what's _transcripts.py do?\",chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is one solution for writing a new Python code to work on Bilibili, referring to _transcripts.py?One possible solution for writing a new Python code to work on Bilibili is to use the Bilibili API. The Bilibili API allows you to interact with Bilibili's services and retrieve various data, including video information and subtitles.\n",
      "\n",
      "To get started, you can use the `requests` library in Python to make HTTP requests to the Bilibili API endpoints. You will need to authenticate and obtain an access token to access certain resources.\n",
      "\n",
      "Here is an example of how you can retrieve video information and subtitles using the Bilibili API:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "\n",
      "# Set up the API endpoint and parameters\n",
      "api_url = 'https://api.bilibili.com/x/web-interface/view'\n",
      "params = {\n",
      "    'aid': 'your_video_id',\n",
      "}\n",
      "\n",
      "# Make the API request\n",
      "response = requests.get(api_url, params=params)\n",
      "data = response.json()\n",
      "\n",
      "# Extract the video information\n",
      "video_title = data['data']['title']\n",
      "video_description = data['data']['desc']\n",
      "# ...\n",
      "\n",
      "# Retrieve the subtitles\n",
      "subtitles_url = 'https://api.bilibili.com/x/player/v2'\n",
      "subtitles_params = {\n",
      "    'cid': 'your_video_cid',\n",
      "    'bvid': 'your_video_bvid',\n",
      "    'qn': 'your_video_quality',\n",
      "    'type': 'your_subtitle_type',\n",
      "}\n",
      "\n",
      "subtitles_response = requests.get(subtitles_url, params=subtitles_params)\n",
      "subtitles_data = subtitles_response.json()\n",
      "\n",
      "# Extract the subtitles\n",
      "subtitles = subtitles_data['data']['subtitle']['subtitles']\n",
      "for subtitle in subtitles:\n",
      "    subtitle_language = subtitle['lan']\n",
      "    subtitle_text = subtitle['subtitle']\n",
      "    # ...\n",
      "\n",
      "# Process the video information and subtitles as needed\n",
      "# ...\n",
      "```\n",
      "\n",
      "Note that you will need to replace `'your_video_id'`, `'your_video_cid'`, `'your_video_bvid'`, `'your_video_quality'`, and `'your_subtitle_type'` with the actual values for the video you want to retrieve information and subtitles for.\n",
      "\n",
      "Keep in mind that the Bilibili API may have rate limits and restrictions, so make sure to review the API documentation and adhere to any usage guidelines or restrictions.\n",
      "\n",
      "Additionally, this is just a basic example to get you started. Depending on your specific requirements, you may need to explore more API endpoints and parameters to achieve the functionality you need.Q:\n",
      " Refer to _transcripts.py, if i want to write a new python code to work on bilibili, can you give one solution? \n",
      "\n",
      "A:\n",
      " One possible solution for writing a new Python code to work on Bilibili is to use the Bilibili API. The Bilibili API allows you to interact with Bilibili's services and retrieve various data, including video information and subtitles.\n",
      "\n",
      "To get started, you can use the `requests` library in Python to make HTTP requests to the Bilibili API endpoints. You will need to authenticate and obtain an access token to access certain resources.\n",
      "\n",
      "Here is an example of how you can retrieve video information and subtitles using the Bilibili API:\n",
      "\n",
      "```python\n",
      "import requests\n",
      "\n",
      "# Set up the API endpoint and parameters\n",
      "api_url = 'https://api.bilibili.com/x/web-interface/view'\n",
      "params = {\n",
      "    'aid': 'your_video_id',\n",
      "}\n",
      "\n",
      "# Make the API request\n",
      "response = requests.get(api_url, params=params)\n",
      "data = response.json()\n",
      "\n",
      "# Extract the video information\n",
      "video_title = data['data']['title']\n",
      "video_description = data['data']['desc']\n",
      "# ...\n",
      "\n",
      "# Retrieve the subtitles\n",
      "subtitles_url = 'https://api.bilibili.com/x/player/v2'\n",
      "subtitles_params = {\n",
      "    'cid': 'your_video_cid',\n",
      "    'bvid': 'your_video_bvid',\n",
      "    'qn': 'your_video_quality',\n",
      "    'type': 'your_subtitle_type',\n",
      "}\n",
      "\n",
      "subtitles_response = requests.get(subtitles_url, params=subtitles_params)\n",
      "subtitles_data = subtitles_response.json()\n",
      "\n",
      "# Extract the subtitles\n",
      "subtitles = subtitles_data['data']['subtitle']['subtitles']\n",
      "for subtitle in subtitles:\n",
      "    subtitle_language = subtitle['lan']\n",
      "    subtitle_text = subtitle['subtitle']\n",
      "    # ...\n",
      "\n",
      "# Process the video information and subtitles as needed\n",
      "# ...\n",
      "```\n",
      "\n",
      "Note that you will need to replace `'your_video_id'`, `'your_video_cid'`, `'your_video_bvid'`, `'your_video_quality'`, and `'your_subtitle_type'` with the actual values for the video you want to retrieve information and subtitles for.\n",
      "\n",
      "Keep in mind that the Bilibili API may have rate limits and restrictions, so make sure to review the API documentation and adhere to any usage guidelines or restrictions.\n",
      "\n",
      "Additionally, this is just a basic example to get you started. Depending on your specific requirements, you may need to explore more API endpoints and parameters to achieve the functionality you need. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ask(\"Refer to _transcripts.py, if i want to write a new python code to work on bilibili, can you give one solution?\",chat_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
